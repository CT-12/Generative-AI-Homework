{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import google.generativeai as genai\n",
    "from typing import List, Tuple\n",
    "import gradio as gr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set Gemini API Key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Input API KEY\n",
    "GOOGLE_API_KEY = \"\"\n",
    "genai.configure(api_key=GOOGLE_API_KEY)\n",
    "model = genai.GenerativeModel(\"gemini-pro\")\n",
    "\n",
    "# Test if it works\n",
    "try:\n",
    "    model.generate_content(\"test\")\n",
    "    print(\"Set Gemini API successfully!!\")\n",
    "except:\n",
    "    print(\"There seem to be something wrong with API...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1: Summarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Input prompt\n",
    "prompt_for_summarization = \"Please summarize the following article and translate the summarization to chinese for me.\"\n",
    "\n",
    "# Function to clear conversation\n",
    "def reset() -> List:\n",
    "    \"\"\"\n",
    "    Reset the conversation\n",
    "    \"\"\"\n",
    "    return []\n",
    "\n",
    "# Function to call the model to generate content\n",
    "def summarization(prompt: str, article: str, temp: float = 1.0) -> List[Tuple[str, str]]:\n",
    "    '''\n",
    "      * Parameters\n",
    "\n",
    "        - prompt: the prompt that we use in this section\n",
    "\n",
    "        - article: the article to be summarized\n",
    "\n",
    "        - temp: the temperature parameter of this model. Temperature is used to control the output of the chatbot.\n",
    "                The higher the temperature is, the more creative response you will get.\n",
    "    '''\n",
    "    input = f\"{prompt}\\n{article}\"\n",
    "    response = model.generate_content(\n",
    "        input,\n",
    "        generation_config=genai.types.GenerationConfig(temperature=temp),\n",
    "        safety_settings=[\n",
    "          {\"category\": \"HARM_CATEGORY_HARASSMENT\",\"threshold\": \"BLOCK_NONE\",},\n",
    "          {\"category\": \"HARM_CATEGORY_HATE_SPEECH\",\"threshold\": \"BLOCK_NONE\",},\n",
    "          {\"category\": \"HARM_CATEGORY_SEXUALLY_EXPLICIT\",\"threshold\": \"BLOCK_NONE\",},\n",
    "          {\"category\": \"HARM_CATEGORY_DANGEROUS_CONTENT\",\"threshold\": \"BLOCK_NONE\",},\n",
    "          ]\n",
    "    )\n",
    "\n",
    "    return [(input, response.text)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This block construct Gradio UI interface\n",
    "with gr.Blocks() as demo:\n",
    "    gr.Markdown(\n",
    "        \"\"\"\n",
    "        # Summarize any article you like !\n",
    "        \"\"\"\n",
    "    )\n",
    "    with gr.Row():\n",
    "        with gr.Column():\n",
    "            prompt_textbox = gr.Textbox(label=\"Prompt\", interactive=False, value=prompt_for_summarization)\n",
    "            article_textbox = gr.Textbox(label=\"Article\", interactive = True, value = \"三隻小豬長大了，決定要離開家裡獨立生活，不過，為了不要被大野狼吃掉，他們決定自己蓋房子。豬大哥說：「我用稻草蓋房子，一天就蓋好了。」豬二哥說：「我用木頭蓋房子，三天就蓋好了。」豬小弟說：「雖然要花十天，我還是要用磚頭蓋房子。」\\\n",
    "    這一天，大野狼來到稻草屋前大叫：「小豬，快讓我進去。」豬大哥說：「我不要，你會把我吃掉。」大野狼說：「那我就把你的房子吹倒，呼～呼～」，一下子豬大哥的稻草屋就被吹倒，豬大哥趕緊跑到豬二哥家裡。接著，大野狼來到小木屋前大叫：「快開門讓我進去。」兩隻小豬說：「我們才不要開門，你會吃掉我們。」大野狼說：「好，看我用力吹倒你的房子，呼～呼～呼～」豬二哥的小木屋也被吹倒，兩隻小豬趕緊跑到豬小弟家裡。\\\n",
    "    最後，大野狼來到磚頭屋前大叫：「快讓我進去。」三隻小豬說：「不開，不開，我們不要變成你的晚餐。」大野狼說：「等我吹倒你的房子，我就把你們吃掉，呼～呼～呼～呼～」大野狼怎麼吹也吹不倒磚頭屋，最後還因為太用力，腳一滑跌到山下，屋裡的三隻小豬高興地在屋子裡唱歌跳舞，豬小弟說：「哥哥，有了堅固的磚頭屋，我們再也不用怕大野狼了。」\")\n",
    "            sent_button = gr.Button(value=\"Send\")\n",
    "            reset_button = gr.Button(value=\"Reset\")\n",
    "            temperature_slider = gr.Slider(label=\"Temperature\", minimum=0.0, maximum=1.0, step=0.1, value=0.5)\n",
    "        with gr.Column():\n",
    "            chatbot = gr.Chatbot()\n",
    "        \n",
    "        sent_button.click(summarization, inputs=[prompt_textbox, article_textbox, temperature_slider], outputs=[chatbot])\n",
    "        reset_button.click(reset, outputs=[chatbot])\n",
    "\n",
    "demo.launch(debug=True, share=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2: Role play"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Fill in the below two lines: character_for_chatbot and prompt_for_roleplay\n",
    "# The first one is the character you want your chatbot to play\n",
    "# The second one is the prompt to make the chatbot be a certain character\n",
    "character_for_chatbot = \"pirate\"\n",
    "prompt_for_roleplay = \"Please act as a pirate and play role play game with me.\"\n",
    "\n",
    "def reset() -> List[Tuple[str, str]]:\n",
    "    return roleplay([], prompt_for_roleplay)\n",
    "\n",
    "def roleplay(chatbot: List[Tuple[str, str]], user_input: str, temp: float=1.0) -> List[Tuple[str, str]]:\n",
    "    \"\"\"\n",
    "    * Parameters\n",
    "        - chatbot: chat history\n",
    "        - user_input: the user input of each round of conversation\n",
    "        - temp: the temperature parameter of this model. Temperature is used to control the output of the chatbot.\n",
    "              The higher the temperature is, the more creative response you will get.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        messages = []\n",
    "        for input_text, response_text in chatbot:\n",
    "            messages.append({\"role\": \"user\", \"parts\": [input_text]})\n",
    "            messages.append({\"role\": \"model\", \"parts\": [response_text]})\n",
    "        \n",
    "        messages.append({\"role\": \"user\", \"parts\": [user_input]})\n",
    "\n",
    "        response = model.generate_content(\n",
    "          messages,\n",
    "          generation_config=genai.types.GenerationConfig(temperature=temp),\n",
    "          safety_settings=[\n",
    "          {\"category\": \"HARM_CATEGORY_HARASSMENT\",\"threshold\": \"BLOCK_NONE\",},\n",
    "          {\"category\": \"HARM_CATEGORY_HATE_SPEECH\",\"threshold\": \"BLOCK_NONE\",},\n",
    "          {\"category\": \"HARM_CATEGORY_SEXUALLY_EXPLICIT\",\"threshold\": \"BLOCK_NONE\",},\n",
    "          {\"category\": \"HARM_CATEGORY_DANGEROUS_CONTENT\",\"threshold\": \"BLOCK_NONE\",},\n",
    "          ]\n",
    "        )\n",
    "        chatbot.append((user_input, response.text))\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error occured: {e}\")\n",
    "        chatbot.append((input_text, f\"Sorry, an error occured: {e}\"))\n",
    "\n",
    "    return chatbot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_dialogue = roleplay([], prompt_for_roleplay)\n",
    "\n",
    "# This block constructs the Gradio UI interface\n",
    "with gr.Blocks() as demo:\n",
    "    gr.Markdown(\"# Task2: The role play\\n The chatbot wants to play a role game with you, try interacting with it !\")\n",
    "    with gr.Row():\n",
    "        with gr.Column():\n",
    "            description_textbox = gr.Textbox(label=\"The character that the chatbot play\", interactive=True, value=character_for_chatbot)\n",
    "            input_textbox = gr.Textbox(label=\"Input\", interactive=True, value=\"\")\n",
    "            gr.Markdown(\"#  Temperature\\n Temperature is used to control the output of the chatbot. The higher the temperature is, the more creative response you will get.\")\n",
    "            temperature_slider = gr.Slider(0.0, 1.0, 0.7, step = 0.1, label=\"Temperature\")\n",
    "            send_button = gr.Button(value=\"Send\")\n",
    "        with gr.Column():\n",
    "            chatbot = gr.Chatbot(value=first_dialogue)\n",
    "            reset_button = gr.Button(value=\"Reset\")\n",
    "\n",
    "        send_button.click(roleplay, inputs=[chatbot, input_textbox, temperature_slider], outputs=[chatbot])\n",
    "        reset_button.click(reset, outputs=[chatbot])\n",
    "\n",
    "demo.launch(debug = True, share=False) # Turn share=false into true to create a public link"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 3: Customize own chatgpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reset() -> List:\n",
    "    return []\n",
    "def chat(chatbot: List[Tuple[str, str] | None], input: str, temp: float) -> List[Tuple[str, str]]:\n",
    "    \"\"\"\n",
    "    * Parameters\n",
    "        - chatbot: Chat history\n",
    "        - input: The user input of each round of conversation\n",
    "        - temp: The temperature parameter of this model. Temperature is used to control the output of the chatbot\n",
    "    \"\"\"\n",
    "    chat_history = []\n",
    "    for user_input, model_response in chatbot:\n",
    "        chat_history.append({\"role\": \"user\", \"parts\": [user_input]})\n",
    "        chat_history.append({\"role\": \"model\", \"parts\": [model_response]})\n",
    "    chat_history.append({\"role\": \"user\", \"parts\": [input]})\n",
    "\n",
    "    response = model.generate_content(\n",
    "        contents=chat_history,\n",
    "        generation_config=genai.types.GenerationConfig(temperature=temp),\n",
    "        safety_settings=[\n",
    "            {\"category\": \"HARM_CATEGORY_HARASSMENT\",\"threshold\": \"BLOCK_NONE\",},\n",
    "            {\"category\": \"HARM_CATEGORY_HATE_SPEECH\",\"threshold\": \"BLOCK_NONE\",},\n",
    "            {\"category\": \"HARM_CATEGORY_SEXUALLY_EXPLICIT\",\"threshold\": \"BLOCK_NONE\",},\n",
    "            {\"category\": \"HARM_CATEGORY_DANGEROUS_CONTENT\",\"threshold\": \"BLOCK_NONE\",},\n",
    "        ]\n",
    "    )\n",
    "    chatbot.append((input, response.text))\n",
    "\n",
    "    return chatbot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with gr.Blocks() as demo:\n",
    "    gr.Markdown(\"# Chat with Chatbot!!\")\n",
    "    with gr.Row():\n",
    "        with gr.Column():\n",
    "            input_textbox = gr.Textbox(label=\"Input text\", interactive=True)\n",
    "            gr.Markdown(\"# Temperature \\n Temperature is used to control the output of chatbot. The higher the temperature is, the more creative output you will get. \")\n",
    "            temp_slider= gr.Slider(label=\"Temperature\", minimum=0.0, maximum=1.0, step=0.1, value=0.7)\n",
    "            send_button = gr.Button(value=\"Send\")\n",
    "            reset_button = gr.Button(value=\"Reset\")\n",
    "        with gr.Column():\n",
    "            chatbot = gr.Chatbot()\n",
    "        send_button.click(chat, inputs=[chatbot, input_textbox, temp_slider], outputs=[chatbot])\n",
    "        reset_button.click(reset, outputs=[chatbot])\n",
    "\n",
    "demo.launch(debug=True, share=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
